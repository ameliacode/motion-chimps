# MOTION CHIMPS
WAK ent. motion data preprocessing pipeline  
ğŸ¯ objective: extracting mocap via monocular video

---

## ğŸ“ Plan

- [ ] [SOTA - 3d pose estimation](https://github.com/davrempe/contact-human-dynamics): contact+physics-based
- [ ] [SOTA - MotionBERT](https://github.com/Walter0807/MotionBERT)
- [ ] Denoise
- [ ] NPY to BVH [video2bvh](https://github.com/KevinLTT/video2bvh)
- [ ] [fairmotion](https://github.com/facebookresearch/fairmotion)

#### Assignment ğŸ¯ ê¸°ì¡´ ëª¨ë¸(MotionBert)ë¥¼ ê°œì„ ì‹œí‚¤ëŠ” ê²ƒì´ ê´€ê±´
- End Effectorë¬¸ì œë¥¼ estimated ëœ ê²°ê³¼ì—ì„œ ì–´ë–»ê²Œ í•´ê²°?
  - Physics-based(Contact and Human Dynamics from Monocular Video, HuMor)
- Denoise: Estimation timeì„ ê³ ë ¤í•œë‹¤ë©´, Inverse Kinematicsë¡œ ë‹¨ìˆœíˆ í•´ê²°í•˜ê±°ë‚˜, Motion DVAEì™€ ê°™ì´ autoencoderë¡œ í•´ê²°
- Motion editing: Motion/Time warping

## ğŸ”‘ Preliminary Keyword
- Pose estimation
- Motion data extension: Bio Vision Hierarchy
- Kinematics(Forward kinematics, Inverse Kinematics)
- Transformer, Autoencoder

## ğŸ›³ï¸ Onboarding

### Team AI
- Local: Ubuntu(20.04 and up): ìœˆë„ìš°ì—ì„œ í•˜ê³ ì í•œë‹¤ë©´ ê°€ìƒí™˜ê²½ ì‚¬ìš© ê¶Œì¥ [ì°¸ê³ ](https://ingu627.github.io/tips/install_ubuntu/) âš ï¸ ìš©ëŸ‰ 50GB ì°¨ì§€, vscode 18.04 ì§€ì› ì¢…ë£Œ issue
- Colab
- Python â¡ï¸ installation requirementì˜ ê²½ìš° [MotionBert](https://github.com/Walter0807/MotionBERT) ì°¸ê³ í•  ê²ƒ


### Team Frontend
- Python
- Kivy(GUI)
- PyopenGL
  
## ğŸ’â€â™€ï¸ How to MotionBert

MotionBERTëŠ” ë‹¨ì•ˆì¹´ë©”ë¼ë¥¼ ì…ë ¥ìœ¼ë¡œ ë‘ê¸° ë•Œë¬¸ì— multi viewì™€ ë‹¤ë¥´ê²Œ epipolar geometryë¥¼ ì‚¬ìš©í•˜ì§€ X  
ë”°ë¼ì„œ 2D pose estimation(via Alphapose) í›„ì— 3D pose estimation(MotionBert)ë¥¼ í•˜ê²Œ ë¨  
ë¬¸ì œëŠ” Alphaposeì˜ ê²½ìš° estimation ì‹œê°„ì´ ìƒë‹¹íˆ ê¸º â¡ï¸ SOTA 2d pose estimationìœ¼ë¡œ ëŒ€ì²´í•´ì•¼í•¨

> "ì¼ë‹¨ ë¹„ì ¼ ê´€ë ¨ì´ë¼ ê·¸ëŸ°ì§€ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ ì¹˜ê³ ëŠ” êµ‰ì¥íˆ ì‚¬ì´ì¦ˆê°€ ì‘ì•„ì„œ ê³ ì„±ëŠ¥ ê·¸ë˜í”½ì¹´ë“œê°€ ì•„ë‹ˆì–´ë„ ëŒë ¤ë³¼ë§Œ í•˜ë‹¤ëŠ” ì ì€ ê³ ë¬´ì "  

> "íŒŒì¸íŠœë‹ìš© ë°ì´í„°ì…‹ì„ ë§Œë“œëŠ” ê²Œ ê´€ê±´"

- [Benchmark](https://paperswithcode.com/sota/3d-human-pose-estimation-on-human36m)

1. Alphapose ë‚´ colab example+MotionBert ê°€ì´ë“œë¼ì¸ ì°¸ê³ í•´ì„œ alphapose-result.json ìƒì„±í•˜ê¸° (GPUê°€ ì•„ë‹Œ CPUë¡œ ëŒì•„ê°€ëŠ” ë¬¸ì œ..)
2. MotionBert infer_wild.py ì‹¤í–‰

â€» python=3.7 pytorch=1.13 cuda=11.7  
â€» ffmpeg ì„¤ì¹˜í•´ì„œ íŒŒì¼ì„ mp4ë¡œ ë³€í™˜í•  ê²ƒì„ ì¶”ì²œí•¨ â†’ ì¶”í›„ colabì— í†µí•©..?

