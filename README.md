## mocap pipeline
WAK ent. motion data preprocessing pipeline  
ğŸ¤º objective: extracting mocap via monocular video

---

### Plan

- [ ] [SOTA - 3d pose estimation](https://github.com/davrempe/contact-human-dynamics): contact+physics-based
- [ ] [SOTA - MotionBERT](https://github.com/Walter0807/MotionBERT)
- [ ] Denoise
- [ ] NPY to BVH [video2bvh](https://github.com/KevinLTT/video2bvh)
- [ ] [fairmotion](https://github.com/facebookresearch/fairmotion)

### MotionBert

> "ì¼ë‹¨ ë¹„ì ¼ ê´€ë ¨ì´ë¼ ê·¸ëŸ°ì§€ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ ì¹˜ê³ ëŠ” êµ‰ì¥íˆ ì‚¬ì´ì¦ˆê°€ ì‘ì•„ì„œ ê³ ì„±ëŠ¥ ê·¸ë˜í”½ì¹´ë“œê°€ ì•„ë‹ˆì–´ë„ ëŒë ¤ë³¼ë§Œ í•˜ë‹¤ëŠ” ì ì€ ê³ ë¬´ì "  

> "íŒŒì¸íŠœë‹ìš© ë°ì´í„°ì…‹ì„ ë§Œë“œëŠ” ê²Œ ê´€ê±´"

- [Benchmark](https://paperswithcode.com/sota/3d-human-pose-estimation-on-human36m)

1. Alphapose ë‚´ colab example+MotionBert ê°€ì´ë“œë¼ì¸ ì°¸ê³ í•´ì„œ alphapose-result.json ìƒì„±í•˜ê¸° (GPUê°€ ì•„ë‹Œ CPUë¡œ ëŒì•„ê°€ëŠ” ë¬¸ì œ..)
2. MotionBert infer_wild.py ì‹¤í–‰

â€» python=3.7 pytorch=1.13 cuda=11.7  
â€» ffmpeg ì„¤ì¹˜í•´ì„œ íŒŒì¼ì„ mp4ë¡œ ë³€í™˜í•  ê²ƒì„ ì¶”ì²œí•¨ â†’ ì¶”í›„ colabì— í†µí•©..?